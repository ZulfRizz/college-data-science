{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79831b68",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac634d4",
   "metadata": {},
   "source": [
    "## 1. Pendahuluan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc902348",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### 1.1 Pengertian Data Preprocessing\n",
    "\n",
    "**Data preprocessing** merupakan proses fundamental dalam data science yang bertujuan untuk mengubah data mentah (raw data) menjadi format yang bersih, terstruktur, dan siap untuk analisis lebih lanjut. \n",
    "\n",
    "Dalam konteks machine learning, data preprocessing adalah tahap kritis yang menentukan keberhasilan model. Data yang tidak diproses dengan baik dapat menyebabkan model belajar pola yang salah, menghasilkan prediksi yang tidak akurat, dan pada akhirnya gagal memberikan insight yang bermakna."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a4b7ee",
   "metadata": {},
   "source": [
    "\n",
    "### 1.2 Pentingnya Data Preprocessing\n",
    "\n",
    "- **Meningkatkan Kualitas Model**: Data yang bersih dan terstruktur memungkinkan model machine learning belajar pola yang lebih akurat\n",
    "- **Menghindari Bias dan Error**: Preprocessing membantu mengidentifikasi dan menangani anomaly, outlier, dan bias dalam data\n",
    "- **Optimasi Performa**: Data yang telah direduksi dan dinormalisasi dapat mempercepat proses training\n",
    "- **Memastikan Konsistensi**: Standardisasi format data memastikan konsistensi across different data sources\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad715f",
   "metadata": {},
   "source": [
    "## 2. Tahapan Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4606ca9",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 Data Cleaning (Pembersihan Data)\n",
    "\n",
    "#### Menangani Missing Values\n",
    "- **Penghapusan Data**: Cocok untuk dataset besar dimana missing values hanya sebagian kecil\n",
    "- **Imputasi Statistik**: Mengisi nilai yang hilang dengan mean/median (numerik) atau mode (kategorikal)\n",
    "- **Advanced Imputation**: Menggunakan machine learning algorithms untuk memprediksi missing values\n",
    "\n",
    "#### Menangani Outliers\n",
    "**Deteksi Outliers**:\n",
    "- Metode Statistik: Z-score, IQR (Interquartile Range)\n",
    "- Visualisasi: Box plots, scatter plots\n",
    "- Machine Learning: Isolation Forest, DBSCAN clustering, ABOD, LOF\n",
    "\n",
    "**Penanganan Outliers**:\n",
    "- Removal: Untuk outliers yang jelas merupakan kesalahan\n",
    "- Capping: Membatasi nilai outliers pada batas tertentu\n",
    "- Transformation: Menggunakan log transformation\n",
    "\n",
    "### 2.2 Data Transformation\n",
    "\n",
    "#### Normalization dan Standardization\n",
    "- **Min-Max Scaling**: Mengubah skala data ke range [0, 1] atau [-1, 1]\n",
    "- **Z-score Standardization**: Transformasi data sehingga memiliki mean = 0 dan standard deviation = 1\n",
    "\n",
    "#### Encoding Categorical Data\n",
    "- **One-Hot Encoding**: Mengubah categorical variables menjadi binary vectors\n",
    "- **Label Encoding**: Mengassign numerical values kepada categories\n",
    "- **Target Encoding**: Menggunakan mean of target variable untuk setiap category\n",
    "\n",
    "#### Feature Engineering\n",
    "- **Polynomial Features**: Membuat interaction terms dan polynomial terms\n",
    "- **Binning**: Mengubah continuous variables menjadi categorical bins\n",
    "- **Domain-Specific Features**: Membuat features berdasarkan domain knowledge\n",
    "\n",
    "### 2.3 Data Reduction\n",
    "\n",
    "#### Dimensionality Reduction\n",
    "- **Principal Component Analysis (PCA)**: Linear transformation yang mengurangi dimensionality\n",
    "- **t-SNE dan UMAP**: Nonlinear techniques untuk visualisasi\n",
    "- **Feature Selection**: Filter Methods, Wrapper Methods, Embedded Methods\n",
    "\n",
    "#### Dataset Reduction\n",
    "- **Sampling Techniques**: Random sampling, Stratified sampling\n",
    "- **Aggregation**: Mengaggregate data ke level yang lebih tinggi\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2564287a",
   "metadata": {},
   "source": [
    "## 3. Best Practices dan Tips Praktis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf7d840",
   "metadata": {},
   "source": [
    "### Workflow Management\n",
    "- **Reproducibility**: Selalu dokumentasikan semua preprocessing steps\n",
    "- **Pipeline Development**: Bangun automated pipelines untuk konsistensi\n",
    "- **Version Control**: Gunakan version control untuk preprocessing scripts\n",
    "\n",
    "### Common Pitfalls\n",
    "- **Data Leakage**: Hindari menggunakan information dari test set dalam preprocessing\n",
    "- **Over-engineering**: Jangan membuat features yang terlalu complex\n",
    "- **Ignoring Domain Context**: Selalu pertimbangkan domain knowledge\n",
    "\n",
    "### Validation Strategies\n",
    "- **Cross-validation**: Implementasikan preprocessing dalam setiap cross-validation fold\n",
    "- **Monitoring**: Terus monitor impact of preprocessing pada model performance\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa2666d",
   "metadata": {},
   "source": [
    "## 4. Kesimpulan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bb16dd",
   "metadata": {},
   "source": [
    "**Data preprocessing** bukanlah tugas tunggal, melainkan serangkaian langkah penting yang saling terkait untuk memastikan data siap digunakan. Dari pembersihan data mentah hingga transformasi dan reduksi, setiap tahap memainkan peran vital dalam membangun fondasi yang kuat untuk analisis data dan machine learning. Mengabaikan proses ini sering kali menjadi penyebab utama kegagalan proyek data science. Oleh karena itu, pemahaman yang mendalam tentang setiap tahapan dan teknik di dalamnya adalah kunci untuk menghasilkan model yang akurat, efisien, dan andal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "156c7d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q pycaret pandas sqlalchemy\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "178f0044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "host =\"localhost\"\n",
    "password = \"root\"\n",
    "port = \"5432\"\n",
    "usn = \"postgres\"\n",
    "\n",
    "# --- Koneksi ke DB1 (sepal) ---\n",
    "conn1 = create_engine(f\"postgresql+psycopg2://{usn}:{password}@{host}:{port}/iris-1\")\n",
    "\n",
    "# --- Koneksi ke DB2 (petal) ---\n",
    "conn2 = create_engine(f\"postgresql+psycopg2://{usn}:{password}@{host}:{port}/iris-2\")\n",
    "\n",
    "# --- Ambil data dari masing-masing database ---\n",
    "iris_sepal = pd.read_sql(\n",
    "    \"SELECT * FROM iris_sepal\",\n",
    "    conn1\n",
    ")\n",
    "\n",
    "iris_petal = pd.read_sql(\n",
    "    \"SELECT * FROM iris_petal\",\n",
    "    conn2\n",
    ")\n",
    "\n",
    "# --- Gabungkan ---\n",
    "iris_full = pd.concat([iris_sepal, iris_petal], axis=1)\n",
    "\n",
    "# --- Simpan ke CSV ---\n",
    "iris_full.to_csv(\"csv/iris_full.csv\", index=False)\n",
    "\n",
    "# --- Cek hasil ---\n",
    "iris_full.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
